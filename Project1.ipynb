{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f72f561",
   "metadata": {},
   "source": [
    "You can use this notebook to write the ML pipeline for the classification of the galaxies in the GALAXYZOO dataset or create a folder with different files associated to the different steps of the ML pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15be4be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "#import Random forest classifiers\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02232e77",
   "metadata": {},
   "source": [
    "# Downloading the Galaxy Zoo Dataset\n",
    "\n",
    "You can find the dataset from the Github repository at the url:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c8190c",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/competitions/galaxy-zoo-the-galaxy-challenge/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0aed504-3ba4-4e6c-8cf2-6a7712020c11",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b76134-4824-4115-b3a5-de1e7775b202",
   "metadata": {},
   "source": [
    "##### Create a data frame with columns for objid and the corresponding assest_id.  \n",
    "- asset_id: an integer that corresponds to the filename of the image of a particular galaxy.\n",
    "- objid is the designation of the galaxy, e.g. galaxy 587722981741363294"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f46a77d-db1f-42e7-a8ba-f857afbc66dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                objid  asset_id\n",
      "0  587722981736120347         1\n",
      "1  587722981736579107         2\n",
      "2  587722981741363294         3\n",
      "3  587722981741363323         4\n",
      "4  587722981741559888         5\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 355990 entries, 0 to 355989\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count   Dtype\n",
      "---  ------    --------------   -----\n",
      " 0   objid     355990 non-null  int64\n",
      " 1   asset_id  355990 non-null  int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 5.4 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# get the objid and corresponding asset_id from gz2_filename_mapping.csv\n",
    "columns_to_keep = ['objid', 'asset_id']\n",
    "\n",
    "# Read the selected columns from the file\n",
    "name_map = pd.read_csv(\"data/gz2_filename_mapping.csv\", usecols=columns_to_keep)\n",
    "\n",
    "# display the first few rows\n",
    "print(name_map.head(5))\n",
    "\n",
    "name_map.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7deebcc-b02f-4779-bc8e-bfbbedd33e8d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb15ac7-997c-4b6d-bccf-1561fe270f2f",
   "metadata": {},
   "source": [
    "#### Create a data frame with dr7objid and corresponding label. \n",
    "- dr7objid gives the galaxy designation same as objid from the previous data frame.\n",
    "- label correspond to some classification of the galaxy based on its shape and morphology. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00ea2dd3-b5c3-4130-a520-6ab040a9f35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                objid gz2class\n",
      "0  588017703996096547    SBb?t\n",
      "1  587738569780428805      Ser\n",
      "2  587735695913320507     Sc+t\n",
      "3  587742775634624545   SBc(r)\n",
      "4  587732769983889439      Ser\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 243500 entries, 0 to 243499\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   objid     243500 non-null  int64 \n",
      " 1   gz2class  243500 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# select columns dr7objid and gz2class from zoo2MainSpecz.csv\n",
    "columns_to_keep = ['dr7objid', 'gz2class']\n",
    "\n",
    "# Read the selected columns from the file\n",
    "labels = pd.read_csv(\"data/zoo2MainSpecz.csv\", usecols=columns_to_keep)\n",
    "\n",
    "# change the name of column dr7objid to objid for merging later\n",
    "labels.rename(columns={'dr7objid':'objid'}, inplace=True)\n",
    "\n",
    "# display\n",
    "print(labels.head(5))\n",
    "\n",
    "labels.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ad74d7-4b27-47fa-9b20-38c423d4130c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb83bd6-9489-413e-9117-b612c4f8f1b3",
   "metadata": {},
   "source": [
    "1. Convert array of pixels in rows of a tabular dataset,\n",
    "   using single pixels as feature columns and the intensities as values measured "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f68b5dfd-d587-4fdb-abae-64b3b9f02dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  asset_id   0  1  2  3  4   5   6   7   8  ...  179766  179767  179768  \\\n",
      "0    97848   6  5  3  2  3   4   5   6   5  ...       6       7       8   \n",
      "1   161420   8  7  7  8  9  12  14  16  25  ...       2       4       2   \n",
      "2    17129   3  4  5  6  6   6   6   5   5  ...       1       1       6   \n",
      "3   246153  11  7  2  0  0   3   5   5   5  ...       3       4       5   \n",
      "4   167167   1  1  1  1  1   1   1   1   0  ...       3       3       1   \n",
      "\n",
      "   179769  179770  179771  179772  179773  179774  179775  \n",
      "0       7       6       5       3       2       1       0  \n",
      "1       1       0       0       0       0       0       0  \n",
      "2       3       1       1       1       3       4       4  \n",
      "3       4       2       1       1       2       4       5  \n",
      "4       1       2       3       3       2       2       1  \n",
      "\n",
      "[5 rows x 179777 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Columns: 179777 entries, asset_id to 179775\n",
      "dtypes: object(1), uint8(179776)\n",
      "memory usage: 17.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Sequential implementation. Loops through one image at a time. This is embarassingly \n",
    "# parallelizable. The task which here consists of 1. processing images, converting to grayscale \n",
    "# and flattening pixel values is CPU-bound, ie performance is determined promarily by how\n",
    "# CPU can process it in contrast to I/O bound. \n",
    "# We can parallelize using Multiprocessing library or Dask. \n",
    "\n",
    "import os \n",
    "from PIL import Image, ImageOps\n",
    "from numpy import asarray\n",
    "\n",
    "# Directory containing the images\n",
    "image_dir = \"data/images\"\n",
    "\n",
    "# List to store image data \n",
    "image_data = []\n",
    "image_names = []\n",
    "\n",
    "# Iterate over all files in the directory \n",
    "for filename in os.listdir(image_dir):\n",
    "    if filename.endswith(('.jpg', '.png')): #filter the image files\n",
    "        image_path = os.path.join(image_dir, filename)\n",
    "\n",
    "        # Open image and convert to grayscale\n",
    "        img = Image.open(image_path)\n",
    "        img_gray = ImageOps.grayscale(img)\n",
    "\n",
    "        # Convert to a numpy array and flatter it to 1D\n",
    "        img_array = np.asarray(img_gray).flatten()\n",
    "\n",
    "        #store the image data and filename\n",
    "        image_data.append(img_array)\n",
    "\n",
    "        # Extract the base name without the extension\n",
    "        image_name = os.path.splitext(filename)[0] # Get only the root, ie w/o extension\n",
    "    \n",
    "        image_names.append(image_name)\n",
    "\n",
    "# convert to DataFrame\n",
    "image_data = pd.DataFrame(image_data)\n",
    "image_data.insert(0, \"asset_id\", image_names) # NOTE: asset_id values are object type. Need to convert to int64 before merging later. \n",
    "# print(image_data['asset_id'].dtype)\n",
    "\n",
    "#display the data frame\n",
    "print(image_data.head())\n",
    "image_data.info()\n",
    "\n",
    "# Save to CSV\n",
    "#image_data(\"image_pixel_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d7633cf-eddf-465e-bb60-e857ebbafb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                objid  asset_id gz2class\n",
      "0  587722981741363294         3       Ei\n",
      "1  587722981741363323         4       Sc\n",
      "2  587722981741559888         5       Er\n",
      "3  587722981741625481         6       Er\n",
      "4  587722981741625484         7       Ei\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 243500 entries, 0 to 243499\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   objid     243500 non-null  int64 \n",
      " 1   asset_id  243500 non-null  int64 \n",
      " 2   gz2class  243500 non-null  object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 5.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Merge labels and name_map dataframes to map asset_id to gz2class\n",
    "# merge based on objid. use an inner join (only matching rows) \n",
    "# since only a subset of points in labels are in name_map, ann inner join \n",
    "# will include the rows from name_map that have matching gz2class values\n",
    "# this will avoid NaNs\n",
    "\n",
    "labels_mapped = pd.merge(name_map, labels, on='objid', how='inner' ) \n",
    "\n",
    "print(labels_mapped.head(5))\n",
    "\n",
    "labels_mapped.info() # should have the same number of rows as the dataframe labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2019b719-248f-40c9-aa87-8b08656691eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                objid  asset_id   0  1  2  3  4   5   6   7  ...  179767  \\\n",
      "0  587722981741363294         3   6  5  3  2  3   4   5   6  ...       7   \n",
      "1  587722981741363323         4   8  7  7  8  9  12  14  16  ...       4   \n",
      "2  587722981741559888         5   3  4  5  6  6   6   6   5  ...       1   \n",
      "3  587722981741625481         6  11  7  2  0  0   3   5   5  ...       4   \n",
      "4  587722981741625484         7   1  1  1  1  1   1   1   1  ...       3   \n",
      "\n",
      "   179768  179769  179770  179771  179772  179773  179774  179775  gz2class  \n",
      "0       8       7       6       5       3       2       1       0        Ei  \n",
      "1       2       1       0       0       0       0       0       0        Sc  \n",
      "2       6       3       1       1       1       3       4       4        Er  \n",
      "3       5       4       2       1       1       2       4       5        Er  \n",
      "4       1       1       2       3       3       2       2       1        Ei  \n",
      "\n",
      "[5 rows x 179779 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Columns: 179779 entries, objid to gz2class\n",
      "dtypes: int64(2), object(1), uint8(179776)\n",
      "memory usage: 17.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Merge labels_mapped with image_data to insert gz2class columnt to the latter \n",
    "# Merge based on asset_id and use an inner join. image_data which is our \n",
    "# main data frame will only have, in general, a subset of data points (galaxies)\n",
    "# in labels_mapped. \n",
    "\n",
    "# convert asset_id values in image_data from object to int64 before mergeing\n",
    "image_data['asset_id'] = labels_mapped['asset_id'].astype(int)\n",
    "\n",
    "#merge\n",
    "galaxy_data = pd.merge(labels_mapped, image_data, on='asset_id', how='inner' ) \n",
    "\n",
    "# Move gz2class to the last position to serve as labels\n",
    "galaxy_data['gz2class'] = galaxy_data.pop('gz2class')  \n",
    "\n",
    "# print\n",
    "print(galaxy_data.head(5))\n",
    "\n",
    "galaxy_data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c395322-29a3-4aa4-811e-07c957af09b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import delayed, compute\n",
    "import os \n",
    "from PIL import Image, ImageOps\n",
    "from numpy import asarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14594255-80eb-45e7-8a75-78e71866d3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                objid  asset_id   0  1  2  3  4   5   6   7  ...  179767  \\\n",
      "0  587722981741363294         3   6  5  3  2  3   4   5   6  ...       7   \n",
      "1  587722981741363323         4   8  7  7  8  9  12  14  16  ...       4   \n",
      "2  587722981741559888         5   3  4  5  6  6   6   6   5  ...       1   \n",
      "3  587722981741625481         6  11  7  2  0  0   3   5   5  ...       4   \n",
      "4  587722981741625484         7   1  1  1  1  1   1   1   1  ...       3   \n",
      "\n",
      "   179768  179769  179770  179771  179772  179773  179774  179775  gz2class  \n",
      "0       8       7       6       5       3       2       1       0        Ei  \n",
      "1       2       1       0       0       0       0       0       0        Sc  \n",
      "2       6       3       1       1       1       3       4       4        Er  \n",
      "3       5       4       2       1       1       2       4       5        Er  \n",
      "4       1       1       2       3       3       2       2       1        Ei  \n",
      "\n",
      "[5 rows x 179779 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Columns: 179777 entries, asset_id to 179775\n",
      "dtypes: object(1), uint8(179776)\n",
      "memory usage: 17.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# parallel implementation of processing the images with DASK\n",
    "\n",
    "# Directory containing images\n",
    "image_dir = \"data/images\"\n",
    "\n",
    "# Get list of image file paths\n",
    "image_files = [\n",
    "    os.path.join(image_dir, f) for f in os.listdir(image_dir)\n",
    "    if f.endswith(('.png', '.jpg'))\n",
    "]\n",
    "\n",
    "# Function to process a single image (Dask version)\n",
    "@delayed\n",
    "def process_image(image_path):\n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "        img_gray = ImageOps.grayscale(img)\n",
    "        img_array = np.asarray(img_gray).flatten()\n",
    "        filename = os.path.basename(image_path)\n",
    "        return os.path.splitext(filename)[0], img_array\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Parallel execution using Dask\n",
    "delayed_results = [process_image(img) for img in image_files]\n",
    "results = compute(*delayed_results)\n",
    "\n",
    "# Filter out failed reads\n",
    "results = [res for res in results if res is not None]\n",
    "\n",
    "# Convert to Dask DataFrame\n",
    "image_names, data = zip(*results)\n",
    "image_data = pd.DataFrame(data)\n",
    "image_data.insert(0, \"asset_id\", image_names)\n",
    "\n",
    "print(galaxy_data.head())\n",
    "\n",
    "image_data.info()\n",
    "# Save to CSV\n",
    "#df.to_csv(\"image_pixel_data.csv\", index=False)\n",
    "#print(\"Processing complete. Data saved to 'image_pixel_data.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45bc66c7-4ae4-4a94-a49b-073d716736ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                objid  asset_id   0  1  2  3  4   5   6   7  ...  179767  \\\n",
      "0  587722981741363294         3   6  5  3  2  3   4   5   6  ...       7   \n",
      "1  587722981741363323         4   8  7  7  8  9  12  14  16  ...       4   \n",
      "2  587722981741559888         5   3  4  5  6  6   6   6   5  ...       1   \n",
      "3  587722981741625481         6  11  7  2  0  0   3   5   5  ...       4   \n",
      "4  587722981741625484         7   1  1  1  1  1   1   1   1  ...       3   \n",
      "\n",
      "   179768  179769  179770  179771  179772  179773  179774  179775  gz2class  \n",
      "0       8       7       6       5       3       2       1       0        Ei  \n",
      "1       2       1       0       0       0       0       0       0        Sc  \n",
      "2       6       3       1       1       1       3       4       4        Er  \n",
      "3       5       4       2       1       1       2       4       5        Er  \n",
      "4       1       1       2       3       3       2       2       1        Ei  \n",
      "\n",
      "[5 rows x 179779 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Columns: 179779 entries, objid to gz2class\n",
      "dtypes: int64(2), object(1), uint8(179776)\n",
      "memory usage: 17.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Merge labels_mapped with image_data to insert gz2class columnt to the latter \n",
    "# Merge based on asset_id and use an inner join. image_data which is our \n",
    "# main data frame will only have, in general, a subset of data points (galaxies)\n",
    "# in labels_mapped. \n",
    "\n",
    "# convert asset_id values in image_data from object to int64 before mergeing\n",
    "image_data['asset_id'] = labels_mapped['asset_id'].astype(int)\n",
    "\n",
    "#merge\n",
    "galaxy_data = pd.merge(labels_mapped, image_data, on='asset_id', how='inner') \n",
    "\n",
    "# Move gz2class to the last position to serve as labels\n",
    "galaxy_data['gz2class'] = galaxy_data.pop('gz2class')  \n",
    "\n",
    "# print\n",
    "print(galaxy_data.head(5))\n",
    "\n",
    "galaxy_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5ecb25-a90d-453d-b5be-ff1d3f5b3251",
   "metadata": {},
   "source": [
    "### 2. Perform EDA and feature preprocessing\n",
    "#### 2.1 Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc70aecf-4e70-41bf-8ec3-999b24cc9bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 179779)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Columns: 179779 entries, objid to gz2class\n",
      "dtypes: int64(2), object(1), uint8(179776)\n",
      "memory usage: 17.1+ MB\n",
      "              objid    asset_id           0           1           2  \\\n",
      "count  1.000000e+02  100.000000  100.000000  100.000000  100.000000   \n",
      "mean   5.877230e+17   54.850000    4.860000    4.910000    4.900000   \n",
      "std    2.318057e+06   30.694117    4.332214    4.022902    4.123106   \n",
      "min    5.877230e+17    3.000000    0.000000    0.000000    0.000000   \n",
      "25%    5.877230e+17   28.750000    2.000000    2.000000    2.000000   \n",
      "50%    5.877230e+17   53.500000    4.000000    4.000000    4.000000   \n",
      "75%    5.877230e+17   81.250000    7.000000    7.000000    7.000000   \n",
      "max    5.877230e+17  108.000000   21.000000   19.000000   19.000000   \n",
      "\n",
      "                3           4           5          6           7  ...  \\\n",
      "count  100.000000  100.000000  100.000000  100.00000  100.000000  ...   \n",
      "mean     5.060000    5.240000    5.280000    5.29000    5.440000  ...   \n",
      "std      4.366586    4.636526    4.771718    4.86649    5.184125  ...   \n",
      "min      0.000000    0.000000    0.000000    0.00000    0.000000  ...   \n",
      "25%      1.750000    2.000000    2.000000    2.00000    2.000000  ...   \n",
      "50%      4.000000    4.000000    4.000000    4.00000    4.500000  ...   \n",
      "75%      8.000000    7.000000    8.000000    7.00000    7.000000  ...   \n",
      "max     21.000000   23.000000   23.000000   29.00000   35.000000  ...   \n",
      "\n",
      "           179766      179767      179768      179769      179770      179771  \\\n",
      "count  100.000000  100.000000  100.000000  100.000000  100.000000  100.000000   \n",
      "mean     6.560000    6.310000    6.450000    6.640000    6.750000    6.570000   \n",
      "std     13.760814   12.478422   10.964014   10.240068    9.475513    8.501046   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      2.000000    2.000000    2.000000    2.000000    2.000000    2.000000   \n",
      "50%      4.000000    4.000000    4.000000    4.000000    4.000000    5.000000   \n",
      "75%      6.250000    6.000000    8.000000    8.000000    9.000000    8.000000   \n",
      "max    120.000000  104.000000   84.000000   73.000000   70.000000   71.000000   \n",
      "\n",
      "           179772      179773      179774      179775  \n",
      "count  100.000000  100.000000  100.000000  100.000000  \n",
      "mean     6.340000    6.250000    6.260000    6.130000  \n",
      "std      8.136736    8.329545    8.187969    7.737688  \n",
      "min      0.000000    0.000000    0.000000    0.000000  \n",
      "25%      2.000000    2.000000    2.000000    2.000000  \n",
      "50%      5.000000    5.000000    4.500000    5.000000  \n",
      "75%      7.000000    8.000000    8.000000    8.000000  \n",
      "max     71.000000   70.000000   69.000000   69.000000  \n",
      "\n",
      "[8 rows x 179778 columns]\n"
     ]
    }
   ],
   "source": [
    "# print\n",
    "#print(galaxy_data.head(4))\n",
    "\n",
    "print(galaxy_data.shape)  # Check dimensions\n",
    "\n",
    "galaxy_data.info()# Check data types & missing values\n",
    "\n",
    "print(galaxy_data.describe())  # Get summary stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d209ce-9ce5-4d47-b095-9b896d35389f",
   "metadata": {},
   "source": [
    "## Adding the symmetry data\n",
    "\n",
    "For this kind of images we can get the symmetry information given some axis in order to add a new data that can be relevant to the data frame. In the python module named `get_symmetry` inside of the `src/` folder we define a pair of functions that given an array of images and the number of axis of symmetry we compute the differences between the intensity values of each pixel pair.\n",
    "\n",
    "The process of getting the symmetries is the following one:\n",
    "\n",
    "1. Get the coordinates of each pixel.\n",
    "2. Rotate the coordinate system in an angle $ \\theta = \\dfrac{i * \\pi }{n\\_axis} $. Where $i$ is a number that goes from 0 to $ \\dfrac{n\\_axis}{2}$ and $n_axis$ is the number of axis of symmetry\n",
    "3. Ignore the data that is outside of a circle of radius width of the image and centered in the middle of the image.\n",
    "4. Split the image in the upper and the lower part, reflect the left part and compute the distance and append to the vector that stores the symmetry values.\n",
    "5. Split the image in the left and right part, reflect the right part and compute the distance and append to the vector that stores the symmetry values.\n",
    "6. Repeat until $i = \\dfrac{n\\_axis}{2}$.\n",
    "7. Return the vector with the symmetry values.\n",
    "\n",
    "For instance, an example of the step 5 is showing on the next image:\n",
    "\n",
    "![images/symmetries.png](images/symmetries.png)\n",
    "\n",
    "Lower the distance (darker the image) more symmetric the original image.\n",
    "\n",
    "Then, we have the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29fcb602-0551-4abd-bb90-500f31be6d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the function from the module\n",
    "from src.get_symmetry import get_all_symmetries\n",
    "\n",
    "# Get the data related with the pixels\n",
    "get_images_column = np.linspace(0, 424*424-1, 424*424)\n",
    "# Reshape the image and assign it to an array\n",
    "images_array = np.reshape(galaxy_data[get_images_column].to_numpy(), shape= (100, 424, 424))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e1bed3d-467b-4bf8-b425-3bea8133d768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.32 s, sys: 2.94 ms, total: 5.32 s\n",
      "Wall time: 5.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Chossing the number of axis\n",
    "axis = 12\n",
    "\n",
    "# Defining the column names\n",
    "columns = [f\"axis-{i}\" for i in range(axis)]\n",
    "\n",
    "# Getting the data\n",
    "sym_data = get_all_symmetries(images_array, axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d8bd4d3-3baa-45e1-a2d7-61263427f0d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>axis-0</th>\n",
       "      <th>axis-1</th>\n",
       "      <th>axis-2</th>\n",
       "      <th>axis-3</th>\n",
       "      <th>axis-4</th>\n",
       "      <th>axis-5</th>\n",
       "      <th>axis-6</th>\n",
       "      <th>axis-7</th>\n",
       "      <th>axis-8</th>\n",
       "      <th>axis-9</th>\n",
       "      <th>axis-10</th>\n",
       "      <th>axis-11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.156401</td>\n",
       "      <td>3.009409</td>\n",
       "      <td>3.103811</td>\n",
       "      <td>2.892341</td>\n",
       "      <td>3.058632</td>\n",
       "      <td>2.953118</td>\n",
       "      <td>3.027720</td>\n",
       "      <td>2.967993</td>\n",
       "      <td>3.000322</td>\n",
       "      <td>2.926460</td>\n",
       "      <td>2.994521</td>\n",
       "      <td>3.047535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.641796</td>\n",
       "      <td>1.303819</td>\n",
       "      <td>1.658116</td>\n",
       "      <td>1.319037</td>\n",
       "      <td>1.594130</td>\n",
       "      <td>1.427220</td>\n",
       "      <td>1.461650</td>\n",
       "      <td>1.397005</td>\n",
       "      <td>1.406018</td>\n",
       "      <td>1.325152</td>\n",
       "      <td>1.346774</td>\n",
       "      <td>1.572757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.561248</td>\n",
       "      <td>1.522000</td>\n",
       "      <td>1.570844</td>\n",
       "      <td>1.507126</td>\n",
       "      <td>1.570376</td>\n",
       "      <td>1.473278</td>\n",
       "      <td>1.543020</td>\n",
       "      <td>1.386470</td>\n",
       "      <td>1.565415</td>\n",
       "      <td>1.459394</td>\n",
       "      <td>1.549250</td>\n",
       "      <td>1.479385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.277803</td>\n",
       "      <td>2.326385</td>\n",
       "      <td>2.291064</td>\n",
       "      <td>2.218331</td>\n",
       "      <td>2.211463</td>\n",
       "      <td>2.204140</td>\n",
       "      <td>2.270179</td>\n",
       "      <td>2.233200</td>\n",
       "      <td>2.266536</td>\n",
       "      <td>2.253306</td>\n",
       "      <td>2.186474</td>\n",
       "      <td>2.227980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.707925</td>\n",
       "      <td>2.724949</td>\n",
       "      <td>2.583573</td>\n",
       "      <td>2.561980</td>\n",
       "      <td>2.578742</td>\n",
       "      <td>2.581371</td>\n",
       "      <td>2.603729</td>\n",
       "      <td>2.548752</td>\n",
       "      <td>2.582389</td>\n",
       "      <td>2.543538</td>\n",
       "      <td>2.658186</td>\n",
       "      <td>2.583715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.273444</td>\n",
       "      <td>3.206663</td>\n",
       "      <td>3.338863</td>\n",
       "      <td>3.147528</td>\n",
       "      <td>3.277448</td>\n",
       "      <td>3.186727</td>\n",
       "      <td>3.231517</td>\n",
       "      <td>3.108599</td>\n",
       "      <td>3.273524</td>\n",
       "      <td>3.139827</td>\n",
       "      <td>3.197606</td>\n",
       "      <td>3.170128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.902690</td>\n",
       "      <td>9.828737</td>\n",
       "      <td>10.817200</td>\n",
       "      <td>10.732172</td>\n",
       "      <td>11.293827</td>\n",
       "      <td>10.550157</td>\n",
       "      <td>11.122019</td>\n",
       "      <td>8.957258</td>\n",
       "      <td>10.515480</td>\n",
       "      <td>8.643106</td>\n",
       "      <td>9.712247</td>\n",
       "      <td>9.090502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           axis-0      axis-1      axis-2      axis-3      axis-4      axis-5  \\\n",
       "count  100.000000  100.000000  100.000000  100.000000  100.000000  100.000000   \n",
       "mean     3.156401    3.009409    3.103811    2.892341    3.058632    2.953118   \n",
       "std      1.641796    1.303819    1.658116    1.319037    1.594130    1.427220   \n",
       "min      1.561248    1.522000    1.570844    1.507126    1.570376    1.473278   \n",
       "25%      2.277803    2.326385    2.291064    2.218331    2.211463    2.204140   \n",
       "50%      2.707925    2.724949    2.583573    2.561980    2.578742    2.581371   \n",
       "75%      3.273444    3.206663    3.338863    3.147528    3.277448    3.186727   \n",
       "max      9.902690    9.828737   10.817200   10.732172   11.293827   10.550157   \n",
       "\n",
       "           axis-6      axis-7      axis-8      axis-9     axis-10     axis-11  \n",
       "count  100.000000  100.000000  100.000000  100.000000  100.000000  100.000000  \n",
       "mean     3.027720    2.967993    3.000322    2.926460    2.994521    3.047535  \n",
       "std      1.461650    1.397005    1.406018    1.325152    1.346774    1.572757  \n",
       "min      1.543020    1.386470    1.565415    1.459394    1.549250    1.479385  \n",
       "25%      2.270179    2.233200    2.266536    2.253306    2.186474    2.227980  \n",
       "50%      2.603729    2.548752    2.582389    2.543538    2.658186    2.583715  \n",
       "75%      3.231517    3.108599    3.273524    3.139827    3.197606    3.170128  \n",
       "max     11.122019    8.957258   10.515480    8.643106    9.712247    9.090502  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Appending to the data frame\n",
    "for i in range(axis):\n",
    "    galaxy_data[columns[i]] = sym_data[:,i]\n",
    "\n",
    "galaxy_data[columns].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0105d921",
   "metadata": {},
   "source": [
    "# Utility function to read Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ba08e7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using PILLOW to convert images to array\n",
    "from PIL import Image, ImageOps\n",
    "from numpy import asarray\n",
    " \n",
    " \n",
    "# load the image and convert into numpy array\n",
    "img = Image.open('data/images/6994.jpg') \n",
    "\n",
    "img_gray = ImageOps.grayscale(img)\n",
    "\n",
    "#img_gray.show() #to check it become gray\n",
    " \n",
    "# asarray() class is used to convert\n",
    "# PIL images into NumPy arraystotal_classifications\n",
    "numpydata = asarray(img_gray)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d16d55",
   "metadata": {},
   "source": [
    "# EDA, feature preprocessing and classification\n",
    "\n",
    "1. Convert array of pixels in rows of a tabular dataset,\n",
    "   using single pixels as feature columns and the intensities as values measured \n",
    "   \n",
    "   \n",
    "2. Perform EDA and feature preprocessing\n",
    "\n",
    "3. Estimate the symmetry of the preprocessed images with respect to 12 axes and add this info to the original data\n",
    "\n",
    "3. Test how much you can reduce the dimensions of the problem with one algorithm between (PCA, kPCA ..)\n",
    "4. Check how many clusters can be associated to the data points joint distribution using tSNE or UMAP\n",
    "\n",
    "5. Build the classifier using Random Forest (play with different  depth and number of trees) or SVC\n",
    "\n",
    "6. Train the classifier\n",
    "\n",
    "7. Predict the class labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4346703d",
   "metadata": {},
   "source": [
    "# Evaluate the accuracy of the Classifier\n",
    "## Plot Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e511344d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:group_project_env] *",
   "language": "python",
   "name": "conda-env-group_project_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
